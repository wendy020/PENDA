{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aca529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import pickle\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "import torch_two_sample.statistics_diff as diff\n",
    "from scipy.stats import norm\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import SubsetRandomSampler, DataLoader\n",
    "\n",
    "from model.model import Model,Generator\n",
    "\n",
    "pkl_dir = \"../level_data\"\n",
    "levels = ['level0', 'level1', 'level3']\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518b2630",
   "metadata": {},
   "outputs": [],
   "source": [
    "def angle(a, b, c):\n",
    "    ang = math.degrees(math.atan2(c[1]-b[1], c[0]-b[0]) - math.atan2(a[1]-b[1], a[0]-b[0]))\n",
    "    return ang + 360 if ang < 0 else ang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed44eb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestAIMSCDataset(data.Dataset):\n",
    "    def __init__(self, file_list, label_list, dim=2, max_frames=48, stride=30, data_type=\"2D\", joint_num=16):\n",
    "        super(TestAIMSCDataset, self).__init__()\n",
    "        self.max_frames = max_frames\n",
    "        \n",
    "        self.clips = []\n",
    "        self.labels = label_list\n",
    "        self.subject_names = []\n",
    "        self.ages = []\n",
    "        self.angles = []\n",
    "        \n",
    "        # keypoint\n",
    "        # 0    3    6    7         10\n",
    "        # RHip LHip nose LShoulder RShoulder\n",
    "        if joint_num == 5:\n",
    "            self.joint_index = [0, 3, 6, 7, 10]\n",
    "            \n",
    "        index = 0\n",
    "        for pkl_filename in file_list:\n",
    "            # read label\n",
    "            name = os.path.splitext(os.path.basename(pkl_filename))[0]\n",
    "            ID = int(name.split('_')[0])\n",
    "            age = name.split('_')[1]\n",
    "            age = int(float(age.split('m')[0]))\n",
    "            age_aug = np.ones((1, 10)) * age / 14.\n",
    "            self.ages.append(age_aug)\n",
    "            level = int(pkl_filename.split(\"3D/level\")[1][:1])\n",
    "            level = 2 if level == 3 else level\n",
    "\n",
    "            # read skeletons\n",
    "            if data_type == \"3D\":\n",
    "                skeleton_dict = np.load(pkl_filename)\n",
    "            else:\n",
    "                rfile = open(pkl_filename, \"rb\")\n",
    "                skeleton_dict = pickle.load(rfile)\n",
    "\n",
    "            skeleton_np = np.zeros((len(skeleton_dict), joint_num, dim))\n",
    "            head_angle = 0\n",
    "            for i in range(len(skeleton_dict)):\n",
    "                if dim == 2 and data_type != \"3D\":\n",
    "                    sk = skeleton_dict[i][re_order_indices]\n",
    "                elif joint_num == 5:\n",
    "                    sk = skeleton_dict[i][self.joint_index]\n",
    "                else:\n",
    "                    sk = skeleton_dict[i]\n",
    "                    \n",
    "                if joint_num == 5:\n",
    "                    head_angle += angle(sk[2], (sk[0]+sk[1])/2, (sk[3]+sk[4])/2)\n",
    "                    G = (skeleton_dict[i][0] + skeleton_dict[i][1]) / 2\n",
    "                else:\n",
    "                    head_angle += angle(sk[2], sk[7], sk[10])\n",
    "                    G = skeleton_dict[i][7]\n",
    "                \n",
    "                skeleton_np[i] = sk - G\n",
    "            head_angle = np.ones(joint_num) * (head_angle / 360) / len(skeleton_dict)\n",
    "            self.angles.append(head_angle)\n",
    "\n",
    "            max_coord = np.max(skeleton_np, axis=(0, 1))\n",
    "            min_coord = np.min(skeleton_np, axis=(0, 1))\n",
    "            skeleton_np = (skeleton_np - min_coord) / (max_coord - min_coord)\n",
    "\n",
    "            age_np = np.ones((len(skeleton_dict), joint_num, 1)) * age / 14.\n",
    "            level_np = np.ones((len(skeleton_dict), joint_num, 1)) * level / 3.\n",
    "            skeleton_np = np.concatenate((skeleton_np, age_np, level_np), axis=2)\n",
    "            \n",
    "            skeletons = []\n",
    "\n",
    "            # fix the number of frames\n",
    "            frame_data = np.zeros((max_frames, joint_num, dim+2))\n",
    "            if max_frames < len(skeleton_dict): # drop last k frames with 1 step\n",
    "                step = len(skeleton_dict) // max_frames\n",
    "                compensation = len(skeleton_dict) - (max_frames * step)\n",
    "                j, k = 0, 0\n",
    "                for i in range(len(skeleton_dict)):\n",
    "                    if(i == j):\n",
    "                        frame_data[k] = skeleton_np[i]\n",
    "                        if k < (max_frames - compensation):\n",
    "                            j = j + step\n",
    "                        else:\n",
    "                            j = j + (step + 1)\n",
    "                        k += 1\n",
    "            else: # padding with first k frames\n",
    "                step = max_frames // len(skeleton_dict)\n",
    "                compensation = max_frames - (len(skeleton_dict) * step)\n",
    "                j, repeat_times = 0, 0\n",
    "                for i in range(max_frames):\n",
    "                    frame_data[i] = skeleton_np[j]\n",
    "                    repeat_times += 1\n",
    "                    if j < compensation:\n",
    "                        if (repeat_times % (step + 1)) == 0:\n",
    "                            repeat_times = 0\n",
    "                            j += 1\n",
    "                    else:\n",
    "                        if (repeat_times % step) == 0:\n",
    "                            repeat_times = 0\n",
    "                            j += 1\n",
    "            skeletons.append(frame_data)\n",
    "            \n",
    "            self.clips.append(skeletons)\n",
    "            self.subject_names.append(name)\n",
    "            index += 1\n",
    "            \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        clips = torch.tensor(self.clips[index], dtype=torch.float)\n",
    "        label = torch.tensor(self.labels[index], dtype=torch.float)\n",
    "        subject_name = self.subject_names[index]\n",
    "        head_angle = torch.tensor(self.angles[index], dtype=torch.float)\n",
    "        \n",
    "        return clips, label, subject_name, head_angle\n",
    "        # return clips, subject_name\n",
    "\n",
    "    def __len__(self):\n",
    "        # return len(self.labels)\n",
    "        return len(self.subject_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e5d69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "    alpha = torch.Tensor(np.random.random((real_samples.size(0), 1, 1, 1, 1))).to(device)\n",
    "    # Get random interpolation between real and fake samples\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "    d_interpolates = D(interpolates)\n",
    "    fake = Variable(torch.Tensor(real_samples.shape[0], 1).fill_(1.0), requires_grad=False).to(device)\n",
    "    # Get gradient w.r.t. interpolates\n",
    "    gradients = autograd.grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=fake,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )[0]\n",
    "    # gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradients = gradients.reshape(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d93dd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(max_epoch, critic_step, train_loader, generator, discriminator, optimizer_G, optimizer_D, save_model, model_name):\n",
    "    batches_done = 0\n",
    "    loss_G_plot = []\n",
    "    loss_D_plot = []\n",
    "    best_G_loss = float(\"inf\")\n",
    "    best_D_loss = float(\"inf\")\n",
    "    for epoch in range(max_epoch):\n",
    "        for i, train_data in enumerate(train_loader, 0):\n",
    "            inputs, labels, names, angles = train_data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # (1, data_dim, frames, num_point, num_person)\n",
    "            inputs = inputs.permute(0, 4, 2, 3, 1)\n",
    "            \n",
    "            # Configure input\n",
    "            real_skeleton = inputs\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            optimizer_D.zero_grad()\n",
    "\n",
    "            # Generate a batch of images\n",
    "            fake_skeleton = generator(real_skeleton)\n",
    "\n",
    "            # Real images\n",
    "            real_validity = discriminator(real_skeleton)\n",
    "            # Fake images\n",
    "            fake_validity = discriminator(fake_skeleton)\n",
    "            # Gradient penalty\n",
    "            gradient_penalty = compute_gradient_penalty(discriminator, real_skeleton, fake_skeleton)\n",
    "            # wasserstein distance=-torch.mean(real_validity) + torch.mean(fake_validity)\n",
    "            wasserstein_d = -torch.mean(real_validity) + torch.mean(fake_validity)\n",
    "            # Adversarial loss\n",
    "            d_loss = wasserstein_d + lambda_gp * gradient_penalty\n",
    "\n",
    "            d_loss.backward()\n",
    "            optimizer_D.step()\n",
    "\n",
    "            optimizer_G.zero_grad()\n",
    "\n",
    "            # Train the generator every critic steps\n",
    "            if i % critic_step == 0:\n",
    "\n",
    "                # -----------------\n",
    "                #  Train Generator\n",
    "                # -----------------\n",
    "\n",
    "                # Generate a batch of images\n",
    "                fake_skeleton = generator(real_skeleton)\n",
    "                # Loss measures generator's ability to fool the discriminator\n",
    "                # Train on fake images\n",
    "                fake_validity = discriminator(fake_skeleton)\n",
    "                g_loss = -torch.mean(fake_validity)\n",
    "\n",
    "                g_loss.backward()\n",
    "                optimizer_G.step()\n",
    "\n",
    "                print(\n",
    "                    \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "                    % (epoch, max_epoch, i, len(train_loader), d_loss.item(), g_loss.item())\n",
    "                )\n",
    "                \n",
    "                loss_G_plot.append(g_loss.item())\n",
    "                loss_D_plot.append(d_loss.item())\n",
    "                \n",
    "                # update best loss\n",
    "                if d_loss.item() <= 100 and abs(g_loss.item()) <= abs(best_G_loss):\n",
    "                    best_G_loss = g_loss.item()\n",
    "                    \n",
    "                    # save best model\n",
    "                    if save_model and d_loss.item() <= best_D_loss+10 and d_loss.item() <= 100:\n",
    "                        PATH = './weights/wgan_G_best_{}.pth'.format(model_name)\n",
    "                        torch.save(generator.state_dict(), PATH)\n",
    "                        \n",
    "                if abs(d_loss.item()) <= abs(best_D_loss):\n",
    "                    best_D_loss = d_loss.item()\n",
    "\n",
    "                batches_done += critic_step\n",
    "                \n",
    "                \n",
    "    # plot loss\n",
    "    epochs = []\n",
    "    for i in range(len(loss_G_plot)):\n",
    "        epochs.append(i)\n",
    "    plt.title(\"Generator Loss\")\n",
    "    plt.xlabel(\"step\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.plot(epochs, loss_G_plot)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.title(\"Discriminator Loss\")\n",
    "    plt.xlabel(\"step\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.plot(epochs, loss_D_plot)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8a7bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def std(x, mean):\n",
    "    std = 0.0\n",
    "    for i in range(len(x)):\n",
    "        std += (x[i] - mean)**2\n",
    "    std /= len(x)\n",
    "    std = math.sqrt(std)\n",
    "    \n",
    "    return std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f69f0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(x):\n",
    "    mean = 0.0\n",
    "    for i in range(len(x)):\n",
    "        mean += x[i]\n",
    "    mean /= len(x)\n",
    "    \n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933a5538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainClassifier(device, dataset, batch_size, max_epoch, optimizer, criterioin, scheduler, model, data_aug,\n",
    "                    fake_real, pass_path, fail_path, alpha, bootstrap, joint_num):\n",
    "    # load model\n",
    "    if data_aug:\n",
    "        generator_pass = Generator(num_class=1, num_point=joint_num, num_person=1, in_channels=4,\n",
    "                     out_channels=300, frames=96, alpha=alpha)\n",
    "        generator_fail = Generator(num_class=1, num_point=joint_num, num_person=1, in_channels=4,\n",
    "                     out_channels=300, frames=96, alpha=alpha)\n",
    "        PATH_pass = pass_path\n",
    "        PATH_fail = fail_path\n",
    "        generator_pass.load_state_dict(torch.load(PATH_pass))\n",
    "        generator_fail.load_state_dict(torch.load(PATH_fail))\n",
    "        generator_pass.to(device)\n",
    "        generator_fail.to(device)\n",
    "    \n",
    "    m = nn.Sigmoid()\n",
    "\n",
    "    # separate to fold\n",
    "    kfold = KFold(n_splits=5, shuffle=True)\n",
    "    \n",
    "    print(\"dataset size: {}\".format(len(dataset)))\n",
    "    acc_list = []\n",
    "    sen_list = []\n",
    "    spe_list = []\n",
    "    time_list = []\n",
    "    # set train/validation dataset\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
    "        print(\"======================fold {}======================\".format(fold))\n",
    "        train_sampler = SubsetRandomSampler(train_idx)\n",
    "        val_sampler = SubsetRandomSampler(val_idx)\n",
    "        \n",
    "        train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "        val_loader = DataLoader(dataset, batch_size=batch_size, sampler=val_sampler)\n",
    "        \n",
    "        # train\n",
    "        model.train()\n",
    "        \n",
    "        train_acc_list = []\n",
    "        val_acc_list = []\n",
    "        train_loss_list = []\n",
    "        val_loss_list = []\n",
    "        best_acc = 0\n",
    "        for epoch in range(max_epoch):\n",
    "            # train:\n",
    "            # load batch\n",
    "            train_acc = 0\n",
    "            train_TP = 0\n",
    "            train_TN = 0\n",
    "            train_FP = 0\n",
    "            train_FN = 0\n",
    "            total = 0\n",
    "            running_loss = 0.0\n",
    "            for i, train_data in enumerate(train_loader, 0):\n",
    "                inputs, labels, names, angles = train_data\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                # (1, data_dim, frames, num_point, num_person)\n",
    "                inputs = inputs.permute(0, 4, 2, 3, 1)\n",
    "                \n",
    "                # initialize\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                if data_aug:\n",
    "                    # generate new data (pass/fail)\n",
    "                    pass_data = []\n",
    "                    fail_data = []\n",
    "                    for j in range(len(inputs)):\n",
    "                        if labels[j] == 1:\n",
    "                            pass_data.append(inputs[j])\n",
    "                        else:\n",
    "                            fail_data.append(inputs[j])\n",
    "\n",
    "                    # loop until match size\n",
    "                    pass_done = False\n",
    "                    fail_done = False\n",
    "                    \n",
    "                    # compute data size\n",
    "                    total_data_size = int(len(inputs) * (1 + fake_real))\n",
    "                    new_pass_size = int(total_data_size / 2) - len(pass_data)\n",
    "                    # len(fail_data) may greater than total_data_size - int(total_data_size / 2)\n",
    "                    new_fail_size = total_data_size - int(total_data_size / 2) - len(fail_data)                    \n",
    "                    \n",
    "                    # initialize\n",
    "                    if len(pass_data) != 0:\n",
    "                        new_pass = generator_pass(torch.stack(pass_data).to(device))\n",
    "                    if new_fail_size > 0:\n",
    "                        new_fail = generator_fail(torch.stack(fail_data).to(device))\n",
    "                    \n",
    "                    while not pass_done or not fail_done:\n",
    "                        # generate pass data\n",
    "                        if len(pass_data) == 0:\n",
    "                            pass_done = True\n",
    "                            pass\n",
    "                        elif len(new_pass) == 0:\n",
    "                            new_pass = generator_pass(torch.stack(pass_data).to(device))\n",
    "                        elif len(new_pass) < new_pass_size:\n",
    "                            new_pass = torch.cat((new_pass, generator_pass(torch.stack(pass_data).to(device))), dim=0)\n",
    "                        else:\n",
    "                            pass_done = True\n",
    "                            new_pass = new_pass[:new_pass_size]\n",
    "                        \n",
    "                        # generate fail data\n",
    "                        if new_fail_size <= 0:\n",
    "                            fail_done = True\n",
    "                            pass\n",
    "                        elif len(new_fail) < new_fail_size:\n",
    "                            new_fail = torch.cat((new_fail, generator_fail(torch.stack(fail_data).to(device))), dim=0)\n",
    "                        else:\n",
    "                            fail_done = True\n",
    "                            new_fail = new_fail[:new_fail_size]\n",
    "                            \n",
    "                    if len(new_pass) > 0:\n",
    "                        new_data = torch.cat((new_pass, new_fail), dim=0)\n",
    "                    elif new_fail_size > 0:\n",
    "                        new_data = new_fail\n",
    "                    else:\n",
    "                        new_data = new_pass\n",
    "                    \n",
    "                    new_label = torch.tensor([1 for i in range(len(new_pass))]+[0 for i in range(len(new_fail))]).to(device)\n",
    "\n",
    "                    print(\"pass: {}, fail: {}\".format(len(pass_data)+len(new_pass), len(fail_data)+len(new_fail)))\n",
    "                    print(\"new_data size: {}, new_label size: {}\".format(new_data.size(), new_label.size()))\n",
    "\n",
    "                    # drop fail data to match size\n",
    "                    if new_fail_size < 0:\n",
    "                        fail_data = fail_data[:total_data_size-int(total_data_size/2)]\n",
    "                    \n",
    "                    # concat\n",
    "                    # concat inputs if fail data is drop\n",
    "                    if new_fail_size < 0:\n",
    "                        inputs = torch.cat((pass_data, new_data), dim=0)\n",
    "                        labels = torch.tensor([1 for i in range(len(pass_data))]+[0 for i in range(len(fail_data))]).to(device)\n",
    "                    # concat inputs and new data\n",
    "                    concat_data = torch.cat((inputs, new_data), dim=0)\n",
    "                    concat_labels = torch.cat((labels, new_label), dim=0)\n",
    "                    \n",
    "                    # shuffle\n",
    "                    shuffle_index = torch.randperm(len(concat_labels))\n",
    "                    concat_data = concat_data[shuffle_index]\n",
    "                    concat_labels = concat_labels[shuffle_index]\n",
    "                    \n",
    "                elif bootstrap: # bootstrap sampling\n",
    "                    boot_index = np.random.choice(len(inputs), int(len(inputs) * (1 + fake_real)))\n",
    "                    concat_data = [inputs[i] for i in boot_index]\n",
    "                    concat_labels = [labels[i] for i in boot_index]\n",
    "                    concat_data = torch.stack(concat_data).to(device)\n",
    "                    concat_labels = torch.stack(concat_labels).to(device)\n",
    "                    \n",
    "                else: # no data_aug\n",
    "                    concat_data = inputs\n",
    "                    concat_labels = labels\n",
    "\n",
    "                # classify\n",
    "                outputs = model(concat_data)\n",
    "                predicted = outputs[:,0].clone()\n",
    "                predicted[predicted >= 0.5] = 1\n",
    "                predicted[predicted < 0.5] = 0\n",
    "\n",
    "                # compute loss/acc\n",
    "                loss = criterion(m(outputs)[:,0], concat_labels)\n",
    "                running_loss += loss.item()\n",
    "\n",
    "                train_acc += (predicted == concat_labels).sum().item()\n",
    "                for p in range(len(predicted)):\n",
    "                    if predicted[p] == 1 and concat_labels[p] == 1:\n",
    "                        train_TP += 1\n",
    "                    elif predicted[p] == 0 and concat_labels[p] == 0:\n",
    "                        train_TN += 1\n",
    "                    elif predicted[p] == 1 and concat_labels[p] == 0:\n",
    "                        train_FP += 1\n",
    "                    else:\n",
    "                        train_FN += 1\n",
    "#                 print(\"curr acc: {}\".format(train_acc))\n",
    "                total += len(predicted)\n",
    "\n",
    "\n",
    "                # updat weight\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            print(\"[train] epoch: {}, loss: {:.3f}, acc: {:.2f}, total: {}\"\n",
    "                  .format(epoch+1, running_loss/total, (train_acc/total)*100, total))\n",
    "            print(\"sen: {:.2f}, spe: {:.2f}\"\n",
    "                  .format((train_TP/(train_TP+train_FN))*100, (train_TN/(train_TN+train_FP))*100))\n",
    "            train_acc_list.append((train_acc/total)*100)\n",
    "            train_loss_list.append(running_loss/total)\n",
    "            \n",
    "            scheduler.step()\n",
    "            \n",
    "            # validation:\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                \n",
    "                start = time.time()\n",
    "                # load batch\n",
    "                val_loss = 0.0\n",
    "                val_acc = 0\n",
    "                val_TP = 0\n",
    "                val_TN = 0\n",
    "                val_FP = 0\n",
    "                val_FN = 0\n",
    "                total = 0\n",
    "                \n",
    "                # check pass/fail size\n",
    "                pass_size = 0\n",
    "                fail_size = 0\n",
    "                for i, val_data in enumerate(val_loader, 0):\n",
    "                    inputs, labels, names, angles = val_data\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    # (1, data_dim, frames, num_point, num_person)\n",
    "                    inputs = inputs.permute(0, 4, 2, 3, 1)\n",
    "\n",
    "                    pass_size += len(labels[labels==1])\n",
    "                    fail_size += len(labels[labels==0])\n",
    "                    # inference\n",
    "                    outputs = model(inputs)\n",
    "                    predicted = outputs[:,0].clone()\n",
    "                    predicted[predicted >= 0.5] = 1\n",
    "                    predicted[predicted < 0.5] = 0\n",
    "\n",
    "                    # compute loss/acc\n",
    "                    loss = criterion(m(outputs)[:,0], labels)\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "    #                 print(\"predicted:\")\n",
    "    #                 print(predicted)\n",
    "    #                 print(\"labels:\")\n",
    "    #                 print(labels)\n",
    "                    val_acc += (predicted == labels).sum().item()\n",
    "                    for p in range(len(predicted)):\n",
    "                        if predicted[p] == 1 and labels[p] == 1:\n",
    "                            val_TP += 1\n",
    "                        elif predicted[p] == 0 and labels[p] == 0:\n",
    "                            val_TN += 1\n",
    "                        elif predicted[p] == 1 and labels[p] == 0:\n",
    "                            val_FP += 1\n",
    "                        else:\n",
    "                            val_FN += 1\n",
    "                    total += len(predicted)\n",
    "\n",
    "                    end = time.time()\n",
    "                    inference_time = (end - start) / total\n",
    "\n",
    "                print(\"[validation] epoch: {}, loss: {:.3f}, acc: {:.2f}, total: {}, pass:fail={}:{}\"\n",
    "                      .format(epoch+1, val_loss/total, (val_acc/total)*100, total, pass_size, fail_size))\n",
    "                print(\"sen: {:.2f}, spe: {:.2f}, inference time: {:.4f}\"\n",
    "                      .format((val_TP/(val_TP+val_FN))*100, (val_TN/(val_TN+val_FP))*100, inference_time))\n",
    "                val_acc_list.append((val_acc/total)*100)\n",
    "                val_loss_list.append(val_loss/total)\n",
    "\n",
    "                if val_acc/total >= best_acc:\n",
    "                    best_acc = val_acc/total\n",
    "                    PATH = './weights/fold{}_best_gcn.pth'.format(fold)\n",
    "                    torch.save(model.state_dict(), PATH)\n",
    "\n",
    "                if epoch == max_epoch-1:\n",
    "                    acc_list.append(val_acc_list[epoch])\n",
    "                    sen_list.append((val_TP/(val_TP+val_FN))*100)\n",
    "                    spe_list.append((val_TN/(val_TN+val_FP))*100)\n",
    "                    time_list.append(inference_time)\n",
    "            \n",
    "        epochs = [(i) for i in range(max_epoch)]\n",
    "        plt.title(\"Fold {} Accuracy\".format(fold))\n",
    "        plt.plot(epochs, train_acc_list, label=\"train acc\")\n",
    "        plt.plot(epochs, val_acc_list, label=\"val acc\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "            \n",
    "        plt.title(\"Fold {} Loss\".format(fold))\n",
    "        plt.plot(epochs, train_loss_list, label=\"train loss\")\n",
    "        plt.plot(epochs, val_loss_list, label=\"val loss\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    M_acc = mean(acc_list)\n",
    "    print(\"acc :{:.2f}+-{:.2f}\".format(M_acc, std(acc_list, M_acc)))\n",
    "    M_sen = mean(sen_list)\n",
    "    print(\"sen :{:.2f}+-{:.2f}\".format(M_sen, std(sen_list, M_sen)))\n",
    "    M_spe = mean(spe_list)\n",
    "    print(\"spe :{:.2f}+-{:.2f}\".format(M_spe, std(spe_list, M_spe)))\n",
    "    M_time = mean(time_list)\n",
    "    print(\"time :{:.4f}+-{:.4f}\".format(M_time, std(time_list, M_time)))\n",
    "    \n",
    "    return M_acc, M_sen, M_spe, M_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644bc49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_dataset, batch_size, device):\n",
    "    # loop for 5 fold\n",
    "    acc_list = []\n",
    "    sen_list = []\n",
    "    spe_list = []\n",
    "    time_list = []\n",
    "    for fold in range(5):\n",
    "        # load model\n",
    "        PATH = './weights/fold{}_best_gcn.pth'.format(fold)\n",
    "        model.load_state_dict(torch.load(PATH))\n",
    "        model.to(device)\n",
    "        \n",
    "        # load data\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "        \n",
    "        # test\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            \n",
    "            # start time stamp\n",
    "            start = time.time()\n",
    "\n",
    "            test_acc = 0\n",
    "            test_TP = 0\n",
    "            test_TN = 0\n",
    "            test_FP = 0\n",
    "            test_FN = 0\n",
    "            total = 0\n",
    "            for i, test_data in enumerate(test_loader, 0):\n",
    "                inputs, labels, names, angles = test_data\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                # (1, data_dim, frames, num_point, num_person)\n",
    "                inputs = inputs.permute(0, 4, 2, 3, 1)\n",
    "\n",
    "                # inference\n",
    "                outputs = model(inputs)\n",
    "                predicted = outputs[:,0].clone()\n",
    "                predicted[predicted >= 0.5] = 1\n",
    "                predicted[predicted < 0.5] = 0\n",
    "\n",
    "                test_acc += (predicted == labels).sum().item()\n",
    "                for p in range(len(predicted)):\n",
    "                    if predicted[p] == 1 and labels[p] == 1:\n",
    "                        test_TP += 1\n",
    "                    elif predicted[p] == 0 and labels[p] == 0:\n",
    "                        test_TN += 1\n",
    "                    elif predicted[p] == 1 and labels[p] == 0:\n",
    "                        test_FP += 1\n",
    "                    else:\n",
    "                        test_FN += 1\n",
    "                total += len(predicted)\n",
    "\n",
    "                end = time.time()\n",
    "                inference_time = (end - start) / total\n",
    "\n",
    "            print(\"[test] fold: {}, acc: {:.2f}, total: {}\".format(fold, (test_acc/total)*100, total))\n",
    "            print(\"sen: {:.2f}, spe: {:.2f}, inference time: {:.4f}\"\n",
    "                      .format((test_TP/(test_TP+test_FN))*100, (test_TN/(test_TN+test_FP))*100, inference_time))\n",
    "\n",
    "            acc_list.append((test_acc/total)*100)\n",
    "            sen_list.append((test_TP/(test_TP+test_FN))*100)\n",
    "            spe_list.append((test_TN/(test_TN+test_FP))*100)\n",
    "            time_list.append(inference_time)\n",
    "\n",
    "    M = mean(acc_list)\n",
    "    print(\"acc :{:.2f}+-{:.2f}\".format(M, std(acc_list, M)))\n",
    "    M = mean(sen_list)\n",
    "    print(\"sen :{:.2f}+-{:.2f}\".format(M, std(sen_list, M)))\n",
    "    M = mean(spe_list)\n",
    "    print(\"spe :{:.2f}+-{:.2f}\".format(M, std(spe_list, M)))\n",
    "    M = mean(time_list)\n",
    "    print(\"time :{:.4f}+-{:.4f}\".format(M, std(time_list, M)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9686bf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files(filename, search_path):\n",
    "    result = []\n",
    "\n",
    "    # Wlaking top-down from the root\n",
    "    for root, dir, files in os.walk(search_path):\n",
    "        if filename in files:\n",
    "            result.append(os.path.join(root, filename))\n",
    "            \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b064fdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFileName(dir_name):\n",
    "    pos = dir_name.find(\"/\")\n",
    "    while pos != -1:\n",
    "        dir_name = dir_name[pos+1:]\n",
    "        pos = dir_name.find(\"/\")\n",
    "\n",
    "    return dir_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcae45a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Generator(num_class=1, num_point=13, num_person=1, in_channels=4,\n",
    "                 out_channels=300, frames=96)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff0a48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"../../EvoSkeleton-master/data/human3.6M_origin/threeDPose_train.npy\"\n",
    "x = np.load(input_dir, allow_pickle=True)\n",
    "print(x)\n",
    "# subjects = glob(input_dir + \"/*/*/*\") # {level}/{view}/{file}\n",
    "# print(len(subjects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5198f058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss weight for gradient penalty\n",
    "lambda_gp = 10\n",
    "\n",
    "# settings\n",
    "data_dim = 3\n",
    "in_channels = data_dim + 1 # coord. + age\n",
    "out_channels = 300\n",
    "frames = 96\n",
    "stride = 60\n",
    "re_order_indices= [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16]\n",
    "data_type = \"3D\"\n",
    "joint_num = 5\n",
    "\n",
    "max_epoch = 200 # 1000 is enough\n",
    "batch_size = 128\n",
    "lr_G = 1e-4\n",
    "lr_D = 1e-4\n",
    "beta1 = 0\n",
    "beta2 = 0.9\n",
    "critic_step = 5\n",
    "save_model = True\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = Generator(num_class=1, num_point=joint_num, num_person=1, in_channels=in_channels,\n",
    "                 out_channels=out_channels, frames=frames)\n",
    "discriminator = Model(num_class=1, num_point=joint_num, num_person=1, graph=\"graph.h36m.Graph\",\n",
    "                              in_channels=in_channels, out_channels=out_channels, frames=frames)\n",
    "# replace batch normalization with layer normalization\n",
    "# input shape = (batch_size, num_person * in_channels * num_point, frames)\n",
    "discriminator.data_bn = nn.LayerNorm([1 * in_channels * joint_num, frames])\n",
    "\n",
    "generator = generator.to(device)\n",
    "discriminator = discriminator.to(device)\n",
    "\n",
    "# data\n",
    "input_dir = \"{}/3D\".format(pkl_dir)\n",
    "subjects = glob(input_dir + \"/level3/*/*\") # {level}/{view}/{file}\n",
    "\n",
    "sample = subjects\n",
    "label = [(1) for i in range(len(sample))]\n",
    "\n",
    "dataset = TestAIMSCDataset(file_list=sample, label_list=label, dim=data_dim, max_frames=frames, stride=stride,\n",
    "                           data_type=data_type, joint_num=joint_num)\n",
    "train_loader = data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# optimizer\n",
    "# wgan_gp\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr_G, betas=(beta1, beta2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr_D, betas=(beta1, beta2))\n",
    "# wgan\n",
    "# optimizer_G = torch.optim.RMSprop(generator.parameters(), lr=lr_G)\n",
    "# optimizer_D = torch.optim.RMSprop(discriminator.parameters(), lr=lr_D)\n",
    "\n",
    "model_name = \"level3_5_joint\"\n",
    "train(max_epoch, critic_step, train_loader, generator, discriminator, optimizer_G, optimizer_D, save_model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cee1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train: origin + gan\n",
    "# test: origin\n",
    "# try 8 ratio\n",
    "# fake_real_list = [0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75, 2]\n",
    "# fake_real_list = [1]\n",
    "fake_real = 1\n",
    "alpha_list = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "# loop for 8 ratio\n",
    "total_acc_list = []\n",
    "total_sen_list = []\n",
    "total_spe_list = []\n",
    "total_time_list = []\n",
    "for alpha in alpha_list:\n",
    "    print(\"fake_real: {}\".format(fake_real))\n",
    "    print(\"===============================\")\n",
    "    \n",
    "    # dataset\n",
    "    # parse csv\n",
    "    file = pd.read_csv('Pull_to_sit_AIMS_0209.csv')\n",
    "    file_names = np.squeeze(file.values)[:,1]\n",
    "    labels = np.squeeze(file.values)[:,4]\n",
    "\n",
    "    file_list = []\n",
    "    label_list = []\n",
    "\n",
    "    not_exist = 0\n",
    "    invalid = 0\n",
    "    for i in range(len(file_names)):\n",
    "        temp = file_names[i]\n",
    "        if not isinstance(file_names[i], str):\n",
    "            continue\n",
    "        if temp.find(\"\\t\") != -1:\n",
    "            temp = temp[0:-2]\n",
    "        if temp.find(\".mp4\") != -1:\n",
    "            temp = temp[0:-4]\n",
    "\n",
    "        temp = temp + \".npy\"\n",
    "#         temp = temp + \".pkl\"\n",
    "        file_dir = find_files(temp, \"../level_data/3D\")\n",
    "        if len(file_dir) == 0:\n",
    "            print(\"file {} does not exist!\".format(temp))\n",
    "            not_exist += 1\n",
    "        elif not isinstance(labels[i], str) or (labels[i] != '1' and labels[i] != '0'):\n",
    "            print(\"invalid label {}\".format(labels[i]))\n",
    "            invalid += 1\n",
    "        else:\n",
    "            file_list.append(file_dir[0])\n",
    "            if labels[i] == '1':\n",
    "                label_list.append(1)\n",
    "            else:\n",
    "                label_list.append(0)\n",
    "\n",
    "    # drop some fail data to balance with pass data\n",
    "    pass_index = [i for i in range(len(label_list)) if label_list[i] == 1]\n",
    "    pass_size = len(pass_index)\n",
    "\n",
    "    fail_index = [i for i in range(len(label_list)) if label_list[i] == 0]\n",
    "    final_fail = np.random.choice(np.array(fail_index), pass_size, replace=False).tolist()\n",
    "\n",
    "    file_index = pass_index + final_fail\n",
    "\n",
    "    file_list = [file_list[i] for i in file_index]\n",
    "    labels_list = [label_list[i] for i in file_index]\n",
    "\n",
    "    print(file_list)\n",
    "    print(label_list)\n",
    "    print(\"origin data size: {}\".format(len(labels)))\n",
    "    print(\"used data size: {}\".format(len(file_list)))\n",
    "    print(\"number of not exist files: {}\".format(not_exist))\n",
    "    print(\"number of invalid label: {}\".format(invalid))\n",
    "\n",
    "    data_dim = 3\n",
    "    frames = 96\n",
    "    stride = 60\n",
    "    data_type = \"3D\"\n",
    "    joint_num = 13\n",
    "\n",
    "    dataset = TestAIMSCDataset(file_list=file_list, label_list=label_list, dim=data_dim, max_frames=frames, stride=stride,\n",
    "                               data_type=data_type, joint_num=joint_num)\n",
    "\n",
    "    # model\n",
    "    in_channels = data_dim + 2\n",
    "    out_channels = 300\n",
    "    model = Model(num_class=1, num_point=joint_num, num_person=1, graph=\"graph.h36m.Graph\",\n",
    "                                  in_channels=in_channels, out_channels=out_channels, frames=frames)\n",
    "#     model.load_state_dict(torch.load(\"./weights/pull_1.pt\"))\n",
    "    model.to(device)\n",
    "\n",
    "    # parameters\n",
    "    batch_size = 64\n",
    "    max_epoch = 100\n",
    "    optimizer = optim.SGD(model.parameters(), lr=5e-4, momentum=0.9, weight_decay=0)\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "    criterion = nn.BCELoss()\n",
    "#     step_list = [(i) for i in range(100)]\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[60], gamma=0.5)\n",
    "#     scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epoch)\n",
    "    data_aug = False\n",
    "    pass_path = './weights/wgan_G_best_level3_5_joint.pth'\n",
    "    fail_path = './weights/wgan_G_best_all_5_joint.pth'\n",
    "    alpha = alpha\n",
    "    bootstrap = False\n",
    "\n",
    "    # train\n",
    "    acc, sen, spe, inf_time = trainClassifier(device, dataset, batch_size, max_epoch, optimizer, criterion, scheduler,\n",
    "                                              model, data_aug, fake_real, pass_path, fail_path, alpha, bootstrap,\n",
    "                                             joint_num)\n",
    "    \n",
    "    total_acc_list.append(acc)\n",
    "    total_sen_list.append(sen)\n",
    "    total_spe_list.append(spe)\n",
    "    total_time_list.append(inf_time)\n",
    "    \n",
    "print(\"==============final result==============\")\n",
    "print(\"ratio:\\t0.1\\t0.2\\t0.3\\t0.4\\t0.5\\t0.6\\t0.7\\t0.8\\t0.9\\t1\")\n",
    "print(\"acc:\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{:.2f}\"\n",
    "      .format(total_acc_list[0], total_acc_list[1], total_acc_list[2], total_acc_list[3],\n",
    "             total_acc_list[4], total_acc_list[5], total_acc_list[6], total_acc_list[7],\n",
    "             total_acc_list[8], total_acc_list[9]))\n",
    "print(\"sen:\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{:.2f}\"\n",
    "      .format(total_sen_list[0], total_sen_list[1], total_sen_list[2], total_sen_list[3],\n",
    "             total_sen_list[4], total_sen_list[5], total_sen_list[6], total_sen_list[7],\n",
    "             total_sen_list[8], total_sen_list[9]))\n",
    "print(\"spe:\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{:.2f}\"\n",
    "      .format(total_spe_list[0], total_spe_list[1], total_spe_list[2], total_spe_list[3],\n",
    "             total_spe_list[4], total_spe_list[5], total_spe_list[6], total_spe_list[7],\n",
    "             total_spe_list[8], total_spe_list[9]))\n",
    "print(\"acc:\\t{:.4f}\\t{:.4f}\\t{:.4f}\\t{:.4f}\\t{:.4f}\\t{:.4f}\\t{:.4f}\\t{:.4f}\\t{:.4f}\\t{:.4f}\"\n",
    "      .format(total_time_list[0], total_time_list[1], total_time_list[2], total_time_list[3],\n",
    "             total_time_list[4], total_time_list[5], total_time_list[6], total_time_list[7],\n",
    "             total_time_list[8], total_time_list[9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4919e305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake_real ratio 0\n",
    "# 5-fold cross validation 30 times\n",
    "\n",
    "total_acc_list = []\n",
    "total_sen_list = []\n",
    "total_spe_list = []\n",
    "total_time_list = []\n",
    "for i in range(30):\n",
    "    print(\"{} times\".format(i+1))\n",
    "    # dataset\n",
    "    # parse csv\n",
    "    file = pd.read_csv('Pull_to_sit_AIMS_0209.csv')\n",
    "    file_names = np.squeeze(file.values)[:,1]\n",
    "    labels = np.squeeze(file.values)[:,4]\n",
    "\n",
    "    file_list = []\n",
    "    label_list = []\n",
    "\n",
    "    not_exist = 0\n",
    "    invalid = 0\n",
    "    for i in range(len(file_names)):\n",
    "        temp = file_names[i]\n",
    "        if not isinstance(file_names[i], str):\n",
    "            continue\n",
    "        if temp.find(\"\\t\") != -1:\n",
    "            temp = temp[0:-2]\n",
    "        if temp.find(\".mp4\") != -1:\n",
    "            temp = temp[0:-4]\n",
    "\n",
    "        temp = temp + \".npy\"\n",
    "        file_dir = find_files(temp, \"../level_data/3D\")\n",
    "        if len(file_dir) == 0:\n",
    "            print(\"file {} does not exist!\".format(temp))\n",
    "            not_exist += 1\n",
    "        elif not isinstance(labels[i], str) or (labels[i] != '1' and labels[i] != '0'):\n",
    "            print(\"invalid label {}\".format(labels[i]))\n",
    "            invalid += 1\n",
    "        else:\n",
    "            file_list.append(file_dir[0])\n",
    "            if labels[i] == '1':\n",
    "                label_list.append(1)\n",
    "            else:\n",
    "                label_list.append(0)\n",
    "\n",
    "    # drop some fail data to balance with pass data\n",
    "    pass_index = [i for i in range(len(label_list)) if label_list[i] == 1]\n",
    "    pass_size = len(pass_index)\n",
    "\n",
    "    fail_index = [i for i in range(len(label_list)) if label_list[i] == 0]\n",
    "    final_fail = np.random.choice(np.array(fail_index), pass_size, replace=False).tolist()\n",
    "\n",
    "    file_index = pass_index + final_fail\n",
    "\n",
    "    file_list = [file_list[i] for i in file_index]\n",
    "    labels_list = [label_list[i] for i in file_index]\n",
    "\n",
    "    print(file_list)\n",
    "    print(label_list)\n",
    "    print(\"origin data size: {}\".format(len(labels)))\n",
    "    print(\"used data size: {}\".format(len(file_list)))\n",
    "    print(\"number of not exist files: {}\".format(not_exist))\n",
    "    print(\"number of invalid label: {}\".format(invalid))\n",
    "\n",
    "    data_dim = 3\n",
    "    frames = 96\n",
    "    stride = 60\n",
    "    data_type = \"3D\"\n",
    "    joint_num = 13\n",
    "\n",
    "    dataset = TestAIMSCDataset(file_list=file_list, label_list=label_list, dim=data_dim, max_frames=frames, stride=stride,\n",
    "                               data_type=data_type, joint_num=13)\n",
    "\n",
    "    # model\n",
    "    in_channels = data_dim + 1\n",
    "    out_channels = 300\n",
    "    model = Model(num_class=1, num_point=joint_num, num_person=1, graph=\"graph.h36m.Graph\",\n",
    "                                  in_channels=in_channels, out_channels=out_channels, frames=frames)\n",
    "    model.to(device)\n",
    "\n",
    "    # parameters\n",
    "    batch_size = 64\n",
    "    max_epoch = 100\n",
    "    optimizer = optim.SGD(model.parameters(), lr=5e-4, momentum=0.9, weight_decay=0)\n",
    "    criterion = nn.BCELoss()\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[60], gamma=0.5)\n",
    "    data_aug = False\n",
    "    fake_real = 1.25\n",
    "    pass_path = './weights/wgan_G_best_level3_default_para.pth'\n",
    "    fail_path = './weights/wgan_G_best_all_default_para.pth'\n",
    "    alpha = 0.5\n",
    "    bootstrap = True\n",
    "\n",
    "    # train\n",
    "    acc, sen, spe, inf_time = trainClassifier(device, dataset, batch_size, max_epoch, optimizer, criterion, scheduler,\n",
    "                                              model, data_aug, fake_real, pass_path, fail_path, alpha, bootstrap)\n",
    "    \n",
    "    total_acc_list.append(acc)\n",
    "    total_sen_list.append(sen)\n",
    "    total_spe_list.append(spe)\n",
    "    total_time_list.append(inf_time)\n",
    "\n",
    "print(\"==============final result==============\")\n",
    "M = mean(total_acc_list)\n",
    "print(\"acc :{:.2f}+-{:.2f}\".format(M, std(total_acc_list, M)))\n",
    "M = mean(total_sen_list)\n",
    "print(\"sen :{:.2f}+-{:.2f}\".format(M, std(total_sen_list, M)))\n",
    "M = mean(total_spe_list)\n",
    "print(\"spe :{:.2f}+-{:.2f}\".format(M, std(total_spe_list, M)))\n",
    "M = mean(total_time_list)\n",
    "print(\"time :{:.4f}+-{:.4f}\".format(M, std(total_time_list, M)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b0b8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([4, 8, 16, 32])\n",
    "print(torch.pow(a, 1/3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09afdad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline balance pass/fail\n",
    "# 5-fold cross validation 30 times\n",
    "total_acc_list = []\n",
    "total_sen_list = []\n",
    "total_spe_list = []\n",
    "total_time_list = []\n",
    "for i in range(30):\n",
    "    print(\"{} times\".format(i+1))\n",
    "    # dataset\n",
    "    # parse csv\n",
    "    file = pd.read_csv('Pull_to_sit_AIMS_0209.csv')\n",
    "    file_names = np.squeeze(file.values)[:,1]\n",
    "    labels = np.squeeze(file.values)[:,4]\n",
    "\n",
    "    file_list = []\n",
    "    label_list = []\n",
    "\n",
    "    not_exist = 0\n",
    "    invalid = 0\n",
    "    for i in range(len(file_names)):\n",
    "        temp = file_names[i]\n",
    "        if not isinstance(file_names[i], str):\n",
    "            continue\n",
    "        if temp.find(\"\\t\") != -1:\n",
    "            temp = temp[0:-2]\n",
    "        if temp.find(\".mp4\") != -1:\n",
    "            temp = temp[0:-4]\n",
    "\n",
    "        temp = temp + \".npy\"\n",
    "        file_dir = find_files(temp, \"../level_data/3D\")\n",
    "        if len(file_dir) == 0:\n",
    "            print(\"file {} does not exist!\".format(temp))\n",
    "            not_exist += 1\n",
    "        elif not isinstance(labels[i], str) or (labels[i] != '1' and labels[i] != '0'):\n",
    "            print(\"invalid label {}\".format(labels[i]))\n",
    "            invalid += 1\n",
    "        else:\n",
    "            file_list.append(file_dir[0])\n",
    "            if labels[i] == '1':\n",
    "                label_list.append(1)\n",
    "            else:\n",
    "                label_list.append(0)\n",
    "\n",
    "    # drop some fail data to balance with pass data\n",
    "    pass_index = [i for i in range(len(label_list)) if label_list[i] == 1]\n",
    "    pass_size = len(pass_index)\n",
    "\n",
    "    fail_index = [i for i in range(len(label_list)) if label_list[i] == 0]\n",
    "    final_fail = np.random.choice(np.array(fail_index), pass_size, replace=False).tolist()\n",
    "\n",
    "    file_index = pass_index + final_fail\n",
    "\n",
    "    file_list = [file_list[i] for i in file_index]\n",
    "    labels_list = [label_list[i] for i in file_index]\n",
    "\n",
    "    print(file_list)\n",
    "    print(label_list)\n",
    "    print(\"origin data size: {}\".format(len(labels)))\n",
    "    print(\"used data size: {}\".format(len(file_list)))\n",
    "    print(\"number of not exist files: {}\".format(not_exist))\n",
    "    print(\"number of invalid label: {}\".format(invalid))\n",
    "\n",
    "    data_dim = 3\n",
    "    frames = 96\n",
    "    stride = 60\n",
    "    data_type = \"3D\"\n",
    "    joint_num = 13\n",
    "\n",
    "    dataset = TestAIMSCDataset(file_list=file_list, label_list=label_list, dim=data_dim, max_frames=frames, stride=stride,\n",
    "                               data_type=data_type, joint_num=13)\n",
    "\n",
    "    # model\n",
    "    in_channels = data_dim + 1\n",
    "    out_channels = 300\n",
    "    model = Model(num_class=1, num_point=joint_num, num_person=1, graph=\"graph.h36m.Graph\",\n",
    "                                  in_channels=in_channels, out_channels=out_channels, frames=frames)\n",
    "    model.to(device)\n",
    "\n",
    "    # parameters\n",
    "    batch_size = 128\n",
    "    max_epoch = 100\n",
    "    optimizer = optim.SGD(model.parameters(), lr=5e-4, momentum=0.9, weight_decay=0)\n",
    "    criterion = nn.BCELoss()\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[60], gamma=0.5)\n",
    "    data_aug = False\n",
    "    fake_real = 0\n",
    "\n",
    "    # train\n",
    "    acc, sen, spe, inf_time = trainClassifier(device, dataset, batch_size, max_epoch, optimizer, criterion, scheduler, model,\n",
    "                                          data_aug, fake_real)\n",
    "    \n",
    "    total_acc_list.append(acc)\n",
    "    total_sen_list.append(sen)\n",
    "    total_spe_list.append(spe)\n",
    "    total_time_list.append(inf_time)\n",
    "\n",
    "M = mean(total_acc_list)\n",
    "print(\"acc :{:.2f}+-{:.2f}\".format(M, std(total_acc_list, M)))\n",
    "M = mean(total_sen_list)\n",
    "print(\"sen :{:.2f}+-{:.2f}\".format(M, std(total_sen_list, M)))\n",
    "M = mean(total_spe_list)\n",
    "print(\"spe :{:.2f}+-{:.2f}\".format(M, std(total_spe_list, M)))\n",
    "M = mean(total_time_list)\n",
    "print(\"time :{:.4f}+-{:.4f}\".format(M, std(total_time_list, M)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4db4138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate and save skeleton\n",
    "best_generator = Generator()\n",
    "PATH = './weights/wgan_G_best_epoch192.pth'\n",
    "best_generator.load_state_dict(torch.load(PATH))\n",
    "best_generator.to(device)\n",
    "\n",
    "new_data = best_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713a3789",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import mpl_toolkits.mplot3d.axes3d as p3\n",
    "from matplotlib import animation\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = p3.Axes3D(fig)\n",
    "\n",
    "q = np.load(sample[4])\n",
    "q = q[-96:]\n",
    "print(q.shape)\n",
    "\n",
    "q = np.reshape(q, (3, 96, 13))\n",
    "\n",
    "x=np.array(q[0][0])\n",
    "y=np.array(q[1][0])\n",
    "z=np.array(q[2][0])\n",
    "\n",
    "# lines index pair\n",
    "pairs = [[0,1],[0,3],[0,10],[1,2],[3,4],[3,5],[6,7],[6,10],\n",
    "        [7,8],[8,9],[10,11],[11,12]]\n",
    "lines = []\n",
    "for i in range(len(pairs)):\n",
    "    line, = ax.plot(np.take(x, pairs[i]), np.take(y, pairs[i]), np.take(z, pairs[i]))\n",
    "    lines.append(line)\n",
    "\n",
    "points, = ax.plot(x, y, z, 'bo')\n",
    "txt = fig.suptitle('')\n",
    "\n",
    "def update_points(num, q, points, lines):\n",
    "    txt.set_text('num={:d}'.format(num)) # for debug purposes\n",
    "\n",
    "    # calculate the new sets of coordinates here. The resulting arrays should have the same shape\n",
    "    # as the original x,y,z\n",
    "    new_x = q[0][num]\n",
    "    new_y = q[1][num]\n",
    "    new_z = q[2][num]\n",
    "\n",
    "    # update properties\n",
    "    points.set_data(new_x,new_y)\n",
    "    points.set_3d_properties(new_z, 'z')\n",
    "    \n",
    "    for i in range(len(pairs)):\n",
    "        lines[i].set_data(np.take(new_x, pairs[i]),np.take(new_y,pairs[i]))\n",
    "        lines[i].set_3d_properties(np.take(new_z, pairs[i]), 'z')\n",
    "    \n",
    "\n",
    "    # return modified artists\n",
    "    return points,txt\n",
    "\n",
    "ani=animation.FuncAnimation(fig, update_points, frames=96, fargs=(q, points, lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fda5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(ani.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45c08c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
